{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOsi1LCoLHThfDO+MT4aGck"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"BtSCYPLpB3M1"},"source":["import pandas as pd\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RbpeSPTsCUD7"},"source":["RE = \"Solar_PBE\" # Solar_PBE Wind_Wallonie_Elia\n","address = \"https://raw.githubusercontent.com/Jaeik-Jeong/DeepBid/main/data/\"\n","\n","data_train_csv1 = pd.read_csv(address+RE+'_16.csv', index_col=0)\n","data_train_csv2 = pd.read_csv(address+RE+'_17.csv', index_col=0)\n","data_train_csv  = pd.concat([data_train_csv1, data_train_csv2])\n","data_val_csv    = pd.read_csv(address+RE+'_18.csv', index_col=0)\n","data_test_csv   = pd.read_csv(address+RE+'_19.csv', index_col=0)\n","\n","data_price = pd.read_csv(address+'Price_Elia_Imbalance_16_19.csv', index_col=0)\n","data_train_csv['Price(€)'] = data_price['Positive imbalance price'][:len(data_train_csv)]\n","data_val_csv['Price(€)']   = data_price['Positive imbalance price'][len(data_train_csv):len(data_train_csv)+len(data_val_csv)]\n","data_test_csv['Price(€)']  = data_price['Positive imbalance price'][len(data_train_csv)+len(data_val_csv):]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OqARQEqDCsXK"},"source":["# Data Preprocessing\n"," \n","Battery_Size = 0.15 #p.u.\n","unit         = 1 #unit: 15 minute\n"," \n","RE_Capacity1 = max(data_train_csv['Power(MW)'])\n","RE_Capacity2 = max(data_val_csv['Power(MW)'])\n","RE_Capacity3 = max(data_test_csv['Power(MW)'])\n","max_price = max(data_price['Marginal incremental price'])\n"," \n","size_train0 = int(len(data_train_csv)/unit)\n","size_val0   = int(len(data_val_csv)/unit)\n","size_test0  = int(len(data_test_csv)/unit)\n"," \n","data_train0 = []; data_train = []; price_train0 = []; price_train = [];\n","for i in range(size_train0):\n","    data_train0  += [round(pd.Series.mean(data_train_csv['Power(MW)'][i*unit:(i+1)*unit])/RE_Capacity1, 3)]\n","    price_train0 += [round(pd.Series.mean(data_train_csv['Price(€)'][i*unit:(i+1)*unit])/max_price, 3)]\n","    if data_train0[i] > 0: data_train += [data_train0[i]]; price_train += [price_train0[i]]\n"," \n","data_val0 = []; data_val = []; price_val0 = []; price_val = []\n","for i in range(size_val0):\n","    data_val0  += [round(pd.Series.mean(data_val_csv['Power(MW)'][i*unit:(i+1)*unit])/RE_Capacity2, 3)]\n","    price_val0 += [round(pd.Series.mean(data_val_csv['Price(€)'][i*unit:(i+1)*unit])/max_price, 3)]\n","    if data_val0[i] > 0: data_val += [data_val0[i]]; price_val += [price_val0[i]]\n"," \n","data_test0 = []; data_test = []; price_test0 = []; price_test = []\n","for i in range(size_test0):\n","    data_test0  += [round(pd.Series.mean(data_test_csv['Power(MW)'][i*unit:(i+1)*unit])/RE_Capacity3, 3)]\n","    price_test0 += [round(pd.Series.mean(data_test_csv['Price(€)'][i*unit:(i+1)*unit])/max_price, 3)]\n","    if data_test0[i] > 0: data_test += [data_test0[i]]; price_test += [price_test0[i]]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z6GhbTTLCvr4"},"source":["# LSTM\n","\n","n_layers       = 2\n","in_size        = 1\n","hidden_size    = 64\n","out_size       = 1\n","batch_size     = 128\n","learning_rate  = 0.001\n","\n","class LSTM(nn.Module):\n","    def __init__(self):\n","        super(LSTM, self).__init__()\n","        self.fc_in  = nn.Linear(in_size, hidden_size)\n","        self.rnn    = nn.LSTM(hidden_size, hidden_size, n_layers, batch_first=True)\n","        self.fc_out = nn.Linear(hidden_size, out_size)\n","    \n","    def forward(self, x, hidden):\n","        x = F.relu(self.fc_in(x))\n","        x = x.view(1, -1, hidden_size)\n","        x, hidden = self.rnn(x, hidden)\n","        out = self.fc_out(x)\n","        out = F.relu(out.view(-1, out_size))\n","        return out, hidden\n","        \n","def train_net(model, batch, optimizer):\n","    x, h, y = batch[0], batch[1], batch[2]\n","    loss = F.mse_loss(model.forward(x, h)[0], y)\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gr_RiEWYC2hc"},"source":["# Training LSTM\n","\n","total_epoch    = 100\n","print_interval = 1\n","\n","model = LSTM()\n","size_train = len(data_train)\n","size_val = len(data_val)\n","size_test = len(data_test)\n","\n","train_input = np.zeros((size_train-1, 1))\n","train_output = np.zeros((size_train-1, 1))\n","for i in range(size_train-1):\n","    train_input[i,:] = data_train[i]\n","    train_output[i,:] = data_train[i+1]\n","\n","val_input = np.zeros((size_val-1, 1))\n","val_output = np.zeros((size_val-1, 1))\n","for i in range(size_val-1):\n","    val_input[i,:] = data_val[i]\n","    val_output[i,:] = data_val[i+1]\n","\n","test_input = np.zeros((size_test-1, 1))\n","test_output = np.zeros((size_test-1, 1))\n","for i in range(size_test-1):\n","    test_input[i,:] = data_test[i]\n","    test_output[i,:] = data_test[i+1]\n","\n","total_batch = int((size_train-1)/batch_size) + 1\n","pred_train, pred_val, pred_test = [], [], [] # Predicted Value\n","mae_train,  mae_val,  mae_test  = [], [], [] # Mean Absolute Error\n","\n","hidden = (torch.zeros([n_layers, 1, hidden_size], dtype=torch.float), torch.zeros([n_layers, 1, hidden_size], dtype=torch.float))\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","for epoch in range(total_epoch):\n","    for i in range(total_batch):\n","        batch_x = torch.tensor(train_input[batch_size*i:batch_size*(i+1),:] ,dtype=torch.float)\n","        batch_y = torch.tensor(train_output[batch_size*i:batch_size*(i+1),:] ,dtype=torch.float)\n","        batch = [batch_x, hidden, batch_y]\n","        train_net(model, batch, optimizer)\n","        _, hidden = model.forward(batch_x, hidden)\n","        hidden = (hidden[0].detach(), hidden[1].detach())\n","\n","    hidden = (torch.zeros([n_layers, 1, hidden_size], dtype=torch.float), torch.zeros([n_layers, 1, hidden_size], dtype=torch.float))\n","    if epoch == 0 or (epoch+1) % print_interval == 0:\n","        train_predict = model.forward(torch.tensor(train_input, dtype=torch.float), hidden)[0].detach().numpy()\n","        pred_train += [list(train_predict.flatten())]\n","        mae_train  += [list(np.abs(train_predict - train_output).flatten())]\n","        \n","        val_predict = model.forward(torch.tensor(val_input, dtype=torch.float), hidden)[0].detach().numpy()\n","        pred_val += [list(val_predict.flatten())]\n","        mae_val  += [list(np.abs(val_predict - val_output).flatten())]\n","        \n","        test_predict = model.forward(torch.tensor(test_input, dtype=torch.float), hidden)[0].detach().numpy()\n","        pred_test += [list(test_predict.flatten())]\n","        mae_test  += [list(np.abs(test_predict - test_output).flatten())]\n","\n","        MAE_train = round(100*np.mean(mae_train[-1]),2)\n","        MAE_val   = round(100*np.mean(mae_val[-1]),2)\n","        MAE_test  = round(100*np.mean(mae_test[-1]),2)\n","\n","        print(\"epoch: {}\".format(epoch+1))\n","        print(\"MAE_train: {}%\".format(MAE_train).ljust(25), end=\"\")\n","        print(\"MAE_val: {}%\".format(MAE_val).ljust(25), end=\"\")\n","        print(\"MAE_test: {}%\".format(MAE_test).ljust(25))\n","        print(\"------------------------------------------------------------------------------------------\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GoOXTK_TDNmh"},"source":["# Environment\n","\n","E_max   = Battery_Size\n","P_max   = E_max\n","tdelta  = unit/4\n","soc_min = 0.1\n","soc_max = 0.9\n","a0 = -1.031; a1 = 35; a2 = 3.685; a3 = 0.2156; a4 = 0.1178; a5 = 0.3201\n","b0 = 0.1463; b1 = 30.27; b2 = 0.1037; b3 = 0.0584; b4 = 0.1747; b5 = 0.1288\n","c0 = 0.1063; c1 = 62.49; c2 = 0.0437; d0 = 0.0712; d1 = 61.4; d2 = 0.0288\n","N = 130*215*E_max/0.1\n","beta = 10/max_price\n"," \n","select_num = np.argmin(np.mean(mae_val,axis=1))\n","select_train = np.array(pred_train[select_num][:])\n","select_val = np.array(pred_val[select_num][:])\n","select_test = np.array(pred_test[select_num][:])\n","select_test_real = np.array(data_test[1:])\n","select_test_price = np.array(price_test[1:])\n"," \n","E = E_max/2\n","mbe = []\n","reward = []\n","info = []\n","for i in range(len(select_test)):\n","    bid = select_test[i]\n","    gen = select_test_real[i]\n","    rat = 1\n","    imb = select_test_price[i]\n","    \n","    soc = E/E_max\n","    Voc = a0*np.exp(-a1*soc) + a2 + a3*soc - a4*soc**2 + a5*soc**3\n","    Rs  = b0*np.exp(-b1*soc) + b2 + b3*soc - b4*soc**2 + b5*soc**3\n","    Rts = c0*np.exp(-c1*soc) + c2\n","    Rtl = d0*np.exp(-d1*soc) + d2\n","    R   = Rs + Rts + Rtl\n"," \n","    I_cmax = 1000000*E_max*(soc_max - soc)/N/(Voc*tdelta)\n","    I_dmax = 1000000*E_max*(soc - soc_min)/N/(Voc*tdelta)\n","    p_cmax = N*(Voc*I_cmax + I_cmax**2*R)\n","    p_dmax = N*(Voc*I_dmax - I_dmax**2*R)\n"," \n","    P_cmax = p_cmax/1000000; P_dmax = p_dmax/1000000\n","    P_c = min(max(rat*(gen-bid), 0), P_max, P_cmax)\n","    P_d = min(max(rat*(bid-gen), 0), P_max, P_dmax)\n","    p_c = 1000000*P_c/N; p_d = 1000000*P_d/N\n"," \n","    I_c = -(Voc - np.sqrt(Voc**2 + 4*R*p_c))/(2*R)\n","    I_d = (Voc - np.sqrt(Voc**2 - 4*R*p_d))/(2*R)\n","    if not np.isclose(p_c, 0):\n","        eff_c = (Voc*I_c)/p_c\n","        E = E + eff_c*P_c*tdelta\n","        disp = gen - P_c\n","        info += [[gen, round(bid,4), 'C', round(P_c,4), round(disp,4), round(eff_c,4), round(E,4)]]\n","    elif not np.isclose(p_d, 0):\n","        eff_d = p_d/(Voc*I_d)\n","        E = E - (1/eff_d)*P_d*tdelta\n","        disp = gen + P_d\n","        info += [[gen, round(bid,4), 'D', round(P_d,4), round(disp,4), round(eff_d,4), round(E,4)]]\n","    else:\n","        disp = gen\n","        info += [[gen, round(bid,4), 'N', 'N', round(disp,4), 'N', round(E,4)]]\n","    \n","    mbe += [abs(bid - disp)]\n","    reward += [(imb*disp - imb*abs(bid-disp) - beta*(P_c+P_d))*tdelta]\n"," \n","MAE_test = round(100*np.mean(np.abs(select_test_real - select_test)),2)\n","MBE_test = round(100*np.mean(mbe),2)\n","print(\"MAE_test: {}%\".format(MAE_test))\n","print(\"MBE_test: {}%\".format(MBE_test))\n","print(\"REV_test: ${}\".format(round(max_price*RE_Capacity3*np.mean(reward),3)))\n","\n","# pd.DataFrame(select_train).to_csv(RE+\"_Model1_train.csv\")\n","# pd.DataFrame(select_val).to_csv(RE+\"_Model1_val.csv\")\n","# pd.DataFrame(select_test).to_csv(RE+\"_Model1_FB.csv\")"],"execution_count":null,"outputs":[]}]}